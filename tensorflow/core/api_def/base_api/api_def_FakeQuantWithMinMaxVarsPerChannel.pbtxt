op {
  graph_op_name: "FakeQuantWithMinMaxVarsPerChannel"
  summary: "Fake-quantize the \'inputs\' tensor of type float via per-channel floats"
  description: <<END
Fake-quantize the `inputs` tensor of type float per-channel and one of the
shapes: `[d]`, `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max`
of shape `[d]` to `outputs` tensor of same shape as `inputs`.

Attributes

*   `[min; max]` define the clamping range for the `inputs` data.
*   `inputs` values are quantized into the quantization range (
`[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`
when it is true) and then de-quantized and output as floats in `[min; max]`
interval.
*   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.

Before quantization, `min` and `max` values are adjusted with the following
logic.
It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,
the behavior can be unexpected:

*   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.
*   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.
*   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,
`min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.

This operation has a gradient and thus allows for training `min` and `max`
values.
>>> # Create sample input tensor
>>> inputs = tf.random.uniform(shape=(2, 3), minval=-2.0, maxval=2.0, dtype=tf.float32)
>>> 
>>> # Create per-channel min and max values
>>> min_vals = tf.constant([-1.0, -2.0, -0.8], dtype=tf.float32)
>>> max_vals = tf.constant([2.0, 1.5, 3.5], dtype=tf.float32)
>>> 
>>> # Quantize the input tensor
>>> quantized_outputs = tf.quantization.fake_quant_with_min_max_vars_per_channel(
...     inputs, min_vals, max_vals, num_bits=8, narrow_range=False
... )
>>> 
>>> 
>>> print("Input:", inputs)
 Input: tf.Tensor(
[[-1.6714907  1.9085183 -1.0085092]
 [-1.4660316  1.3541527  1.4107189]], shape=(2, 3), dtype=float32)
>>> 
>>> print("\n Output:", quantized_outputs)
 Output: tf.Tensor(
[[-1.         1.4960785 -0.7925491]
 [-1.         1.3588235  1.4164706]], shape=(2, 3), dtype=float32)
END
}
